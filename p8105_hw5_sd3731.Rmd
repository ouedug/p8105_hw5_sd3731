---
title: "p8105_hw5_sd3731"
author: "Susie Dong"
date: "2023-11-13"
output: github_document
---

```{r, message=FALSE}
library(tidyverse)
library(dplyr)

knitr::opts_chunk$set(
	warning = FALSE,
	message = FALSE,
	fig.width = 8, 
	fig.height = 6)

theme_set(theme_minimal())
```

## Problem 1

### Accessing and Describing the Data
1. Load the Data
```{r, message=FALSE}
homicide = read_csv("./data/homicide-data.csv")
```

2. Inspect the Data
The `homicide` dataset includes data on homicide incidents in the United States spanning from 2007 to 2017. It is comprised of `r nrow(homicide)` rows and `r ncol(homicide)` columns.

**Variables**:

- `uid`: unique identifier

- `reported_date`: date of homicide accident

- `victim_last`: last name of victim

- `victim_first`: first name of victim

- `victim_race`: race name of victim

- `victim_age`: age name of victim

- `victim_sex`: sex name of victim

- `city`: city location of homicide accident

- `state`: state location of homicide accident

- `lat`: latitude location of homicide accident

- `lon`: longitude location of homicide accident

- `disposition`: disposition outcome of homicide accident

### Data Manipulation
```{r}
homicide = homicide|>
  mutate(
    city_state = str_c(city, ", ", state)
    )

homicide |> 
        group_by(city) |>
        summarise(count = n()) |>
        knitr::kable(caption = "Total number of homicides")

unsolved_homicides = c("Closed without arrest", "Open/No arrest")
homicide |>
        filter(disposition %in% unsolved_homicides) |>
        group_by(city) |>
        summarise(unsolved_count = n()) |>
        knitr::kable(caption = "Total number of unsolved homicides")
```

### Proportion Test for Baltimore, MD
```{r}
baltimore = homicide |>
  filter(city_state == "Baltimore, MD") |>
   mutate(unsolved = if_else(disposition %in% unsolved_homicides, 1, 0))

prop_test_bal = prop.test(sum(baltimore$unsolved), nrow(baltimore))
prop_test_df = broom::tidy(prop_test_bal)
```

Estimated Proportion: `r prop_test_df$estimate`
Confidence Interval: (`r prop_test_df$conf.low`, `r prop_test_df$conf.high`)

### Proportion Test for All Cities
```{r}
tidy = function(city_name, df){
        city_data = df |> 
                filter(city == city_name) |> 
                mutate(unsolved = if_else(disposition %in% unsolved_homicides, 1, 0))
        prop_test_obj = prop.test(sum(city_data$unsolved), nrow(city_data))
        prop_test_df = broom::tidy(prop_test_obj)
        
        tibble(
                estimate_prop = prop_test_df$estimate,
                conf_low = prop_test_df$conf.low,
                conf_high = prop_test_df$conf.high
        )
}
```

```{r}
cities = homicide$city |> unique()
test_result = tibble(
        city = cities,
        hypo_test = map(cities, tidy, df = homicide)
        ) |> 
        unnest(hypo_test)
test_result |> knitr::kable(caption = "Estimated proportion and CI of unsolved homicides")
```

### Creating the Plot
```{r}
test_result |>
  mutate(city = fct_reorder(city, estimate_prop)) |>
        ggplot(aes(x = city, y = estimate_prop, color = city), width = 100) +
        geom_point() +
        geom_errorbar(aes(ymin = conf_low, ymax = conf_high)) +
        theme_bw() +
        labs(x = "", y = "Proportion Unsolved", title = "Proportion of Unsolved Homicides by City") +
        theme(plot.title = element_text(hjust = 0.5), axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
```


## Problem 2

### Creating a Dataframe of File Names
```{r}
pth = "./data/data2/"

data_df = tibble(
        filename = list.files(pth)
)
```

### Function
```{r}
extract_info = function(filename, pth){
        tibble(
                read_csv(str_c(pth, filename))
        )
}

longitudial_data = data_df |>
        mutate(
                subject_id = str_extract(filename, pattern = "\\d+"),
                arm = str_extract(filename, pattern = "^[a-zA-Z]+"),
                data2 = map(filename, extract_info, pth)
        ) |> 
        unnest(data2)
```

### Creating a Spaghetti Plot
```{r}
longitudial_data |> 
        pivot_longer(starts_with("week_"), names_prefix = "week_", names_to = "week") |>
        mutate(week = as.numeric(week)) |>
        ggplot(aes(x = week, y = value, color = subject_id)) +
        geom_path() +
        theme_bw() +
        labs(x = "Week", y = "Observation Value", title = "Observations Over Time") +
        theme(plot.title = element_text(hjust = 0.5)) + 
        facet_grid(. ~ arm)
```

### Analyzing the Plot
The measurements from the experimental group are typically greater than those from the control group. Additionally, the data from the experimental group displays a rising pattern as time progresses, while the measurements for the control group tend to remain fairly constant.


## Problem 3

```{r}
# Set Up the Simulation
n = 30
sigma = 5
mu = 0:6
num_simulations = 5000
alpha = 0.05

simulate_t_test <- function(mu, n, sigma) {
  sample <- rnorm(n, mean = mu, sd = sigma)
  test_result <- t.test(sample, mu = 0, conf.level = 0.95)
  tidy_result <- broom::tidy(test_result) %>%
    rename(mu_hat = estimate, p_value = p.value)
  return(tidy_result[c("mu_hat", "p_value")])
}

# Perform One-Sample t-Test
simulation_results <- map_dfr(1:num_simulations, ~simulate_t_test(mu, n, sigma))

head(simulation_results)
```

```{r}
# Calculate Power and Average Estimates
mu_list =
  list(
    "mu = 1" = 1,
    "mu = 2" = 2,
    "mu = 3" = 3,
    "mu = 4" = 4,
    "mu = 5" = 5,
    "mu = 6" = 6
  )

results <- map_df(mu_list, function(mu) {
  map_dfr(1:num_simulations, ~simulate_t_test(mu, n, sigma))
}, .id = "mu")

results %>%
  mutate(mu = as.numeric(str_extract(results$mu, "\\d+")))

power_results <- results %>%
  group_by(mu) %>%
  summarise(
    power = mean(p_value < alpha),
    mean_mu_hat = mean(mu_hat),
    mean_mu_rejected = mean(mu_hat[p_value < alpha])
  ) %>%
  ungroup()

# Power plot
power_results %>%
  ggplot(aes(x = mu, y = power, group = 1)) +
  geom_point(color = "turquoise") +
  geom_line(color = "turquoise") +
  labs(title = "Power vs. True µ", 
       x = "True µ", 
       y = "Power")
```

1. Comments:
The graph illustrates that the power of the test grows with an increase in the true value of μ, demonstrating that greater effect sizes correspond to enhanced power. Nonetheless, there is an observable leveling off in power at higher effect sizes, indicating a threshold beyond which additional increases in effect size do not substantially improve the power of the test.

```{r}
# Estimate plot
power_results %>%
  ggplot(aes(x = mu, y = mean_mu_hat, group = 1)) +
  geom_point(color = "coral") +
  geom_line(color = "coral") +
  labs(title = "Average Estimate of µ vs. True µ", 
       x = "True Value of µ", 
       y = "Average Estimate")
```

```{r}
power_results %>%
  ggplot(aes(x = mu)) +
  geom_point(aes(y = mean_mu_hat, group = 1, color = "All Tests")) +
  geom_line(aes(y = mean_mu_hat, group = 1, color = "All Tests")) +
  geom_point(aes(y = mean_mu_rejected, group = 1, color = "Rejected Tests")) +
  geom_line(aes(y = mean_mu_rejected, group = 1, color = "Rejected Tests"))  +
  scale_color_manual(labels = c("All Tests", "Rejected Tests"), 
                     values = c("turquoise", "coral")) +
  labs(title = "Mean Estimate vs. True µ", 
       x = "True µ", 
       y = "Mean Estimate") +
  theme(legend.title = element_blank())
```

2. Answers:
As the true value of μ rises, the average of the sample estimates μ_hat in tests where the null hypothesis is rejected increasingly aligns with the true μ.

Explanation: When μ is relatively small, samples showing a significantly higher μ_hat than the true μ are more likely to lead to the rejection of the null hypothesis, resulting in a higher mean of μ_hat compared to μ. However, as μ increases, samples where μ_hat is closer to μ are more frequently associated with null hypothesis rejections, leading to the mean of μ_hat becoming progressively closer to the true μ.


